{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec8ad0-77a3-4487-b570-9c98e516e7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761807424.953492 15020248 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1761807425.038415 15033091 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761807425.081508 15033094 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2025-10-30 14:57:06.397 Python[46879:15020248] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "W0000 00:00:1761807428.165014 15033092 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas cleared.\n",
      "Canvas cleared.\n",
      "Canvas cleared.\n",
      "Canvas cleared.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 125\u001b[39m, in \u001b[36mAirCanvasApp.update_frame\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_frame\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    124\u001b[39m     \u001b[38;5;66;03m# 1. Capture one frame from webcam\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     ret, frame = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[32m    127\u001b[39m         \u001b[38;5;66;03m# Re-initialize capture if it fails (common on Mac sleep/wake)\u001b[39;00m\n\u001b[32m    128\u001b[39m         \u001b[38;5;28mself\u001b[39m.cap = cv2.VideoCapture(\u001b[32m1\u001b[39m, cv2.CAP_AVFOUNDATION)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Real-time HMI: Air Canvas (Gesture Drawing Board)\n",
    "\n",
    "Features:\n",
    "\n",
    "1. OpenCV captures camera frame at 640x480 resolution. The camera is initialized to robustly handle macOS's Continuity Camera by checking multiple indices.\n",
    "2. PyQt label displays the live camera feed combined with the persistent Canvas Layer.\n",
    "3. MediaPipe detects 21 hand landmarks in VIDEO mode (synchronous).\n",
    "4. HMI Gesture Logic: The system detects a \"Pinch Gesture\" (Index Finger #8 close to Thumb #4) to switch the system state between DRAWING (active) and MOVING (inactive).\n",
    "5. Drawing Layer: Strokes are drawn on a separate, persistent NumPy array (Canvas Layer), which is then blended with the live video frame.\n",
    "6. FPS is computed as average frames per second (stable measurement).\n",
    "7. Motion is smoothed using Exponential Smoothing (α=0.3) to reduce jitter in the drawn lines.\n",
    "\n",
    "Author: Dimas Ahmad Fahreza 113021199\n",
    "Course: Human–Machine Interface\n",
    "Date: October 2025\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PyQt6.QtWidgets import QApplication, QLabel, QWidget, QVBoxLayout, QPushButton, QHBoxLayout\n",
    "from PyQt6.QtGui import QImage, QPixmap\n",
    "from PyQt6.QtCore import Qt, QTimer\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python as mp_python\n",
    "from mediapipe.tasks.python import vision as mp_vision\n",
    "\n",
    "# ============================================================\n",
    "# I. Initialize MediaPipe HandLandmarker in VIDEO mode\n",
    "# ============================================================\n",
    "\n",
    "# Pastikan file 'hand_landmarker.task' ada di direktori yang sama\n",
    "MODEL_PATH = \"hand_landmarker.task\"\n",
    "\n",
    "try:\n",
    "    options = mp_vision.HandLandmarkerOptions(\n",
    "        base_options=mp_python.BaseOptions(model_asset_path=MODEL_PATH),\n",
    "        running_mode=mp_vision.RunningMode.VIDEO,\n",
    "        num_hands=1\n",
    "    )\n",
    "    hand_landmarker = mp_vision.HandLandmarker.create_from_options(options)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Model file '{MODEL_PATH}' not found. Please ensure it is in the same directory.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"ERROR initializing MediaPipe: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ============================================================\n",
    "# II. PyQt6 GUI Application (Air Canvas)\n",
    "# ============================================================\n",
    "\n",
    "class AirCanvasApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"HMI Air Canvas - Gesture Drawing\")\n",
    "        \n",
    "        # Fixed Resolution for consistency\n",
    "        self.FRAME_W, self.FRAME_H = 640, 480\n",
    "        self.setGeometry(100, 100, self.FRAME_W, self.FRAME_H + 50) \n",
    "        \n",
    "        # --- UI Components ---\n",
    "        self.video_label = QLabel(self)\n",
    "        self.video_label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "\n",
    "        self.clear_button = QPushButton(\"Clear Canvas\")\n",
    "        self.clear_button.clicked.connect(self.clear_canvas)\n",
    "        \n",
    "        control_layout = QHBoxLayout()\n",
    "        control_layout.addWidget(self.clear_button)\n",
    "        \n",
    "        main_layout = QVBoxLayout()\n",
    "        main_layout.addWidget(self.video_label)\n",
    "        main_layout.addLayout(control_layout)\n",
    "        self.setLayout(main_layout)\n",
    "\n",
    "        self.cap = cv2.VideoCapture(1, cv2.CAP_AVFOUNDATION)\n",
    "        \n",
    "        if not self.cap.isOpened():\n",
    "            self.cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "            if not self.cap.isOpened():\n",
    "                raise RuntimeError(\"Cannot open webcam. Check system permissions or available camera index.\")\n",
    "        \n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.FRAME_W)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.FRAME_H)\n",
    "            \n",
    "        # --- Canvas and Drawing Variables ---\n",
    "        self.canvas_layer = np.zeros((self.FRAME_H, self.FRAME_W, 3), dtype=np.uint8)\n",
    "        \n",
    "        self.current_x, self.current_y = 0, 0\n",
    "        self.prev_x, self.prev_y = 0, 0\n",
    "        self.is_drawing = False\n",
    "        \n",
    "        self.SMOOTHING_FACTOR = 0.3\n",
    "        self.PINCH_THRESHOLD = 50 \n",
    "\n",
    "        # --- Performance Variables ---\n",
    "        self.fps_start_time = time.time()\n",
    "        self.frame_count = 0\n",
    "        self.fps = 0.0\n",
    "        self.frame_timestamp = 0\n",
    "        \n",
    "        # --- QTimer Loop ---\n",
    "        self.timer = QTimer()\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        self.timer.start(33)\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # Utility Function: Clear the Drawing Layer\n",
    "    # -----------------------------------------------\n",
    "    def clear_canvas(self):\n",
    "        \"\"\"Reset the canvas layer to a blank black image.\"\"\"\n",
    "        self.canvas_layer = np.zeros((self.FRAME_H, self.FRAME_W, 3), dtype=np.uint8)\n",
    "        print(\"Canvas cleared.\")\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # Main Loop: Capture, Process, and Display\n",
    "    # -----------------------------------------------\n",
    "    def update_frame(self):\n",
    "        # 1. Capture one frame from webcam\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            # Re-initialize capture if it fails (common on Mac sleep/wake)\n",
    "            self.cap = cv2.VideoCapture(1, cv2.CAP_AVFOUNDATION)\n",
    "            if not self.cap.isOpened():\n",
    "                return\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret: return\n",
    "\n",
    "        # 2. Preprocessing\n",
    "        frame = cv2.flip(frame, 1) # Mirror effect\n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "        \n",
    "        # 3. Update MediaPipe timestamp (VIDEO mode requirement)\n",
    "        self.frame_timestamp += 33 \n",
    "\n",
    "        # 4. Run detector\n",
    "        results = hand_landmarker.detect_for_video(mp_image, self.frame_timestamp)\n",
    "\n",
    "        # 5. Drawing and Smoothing Logic\n",
    "        if results.hand_landmarks:\n",
    "            for hand_landmarks in results.hand_landmarks:\n",
    "                # Landmark 8: Index Fingertip; Landmark 4: Thumb Tip\n",
    "                x8 = int(hand_landmarks[8].x * w)\n",
    "                y8 = int(hand_landmarks[8].y * h)\n",
    "                x4 = int(hand_landmarks[4].x * w)\n",
    "                y4 = int(hand_landmarks[4].y * h)\n",
    "                \n",
    "                # a. Apply Exponential Smoothing (for drawing point)\n",
    "                self.current_x = int((1 - self.SMOOTHING_FACTOR) * self.current_x + self.SMOOTHING_FACTOR * x8)\n",
    "                self.current_y = int((1 - self.SMOOTHING_FACTOR) * self.current_y + self.SMOOTHING_FACTOR * y8)\n",
    "                \n",
    "                # b. Calculate distance for Pinch Detection\n",
    "                pinch_distance = np.sqrt((x8 - x4)**2 + (y8 - y4)**2)\n",
    "                \n",
    "                # c. Determine Drawing Mode\n",
    "                if pinch_distance < self.PINCH_THRESHOLD:\n",
    "                    self.is_drawing = True\n",
    "                    # Draw a visual indicator (red circle) for drawing mode\n",
    "                    cv2.circle(frame, (self.current_x, self.current_y), 5, (0, 0, 255), -1) \n",
    "                else:\n",
    "                    self.is_drawing = False\n",
    "                    # Draw a visual indicator (green circle) for moving mode\n",
    "                    cv2.circle(frame, (self.current_x, self.current_y), 5, (0, 255, 0), -1) \n",
    "                    \n",
    "                # d. Perform Drawing on the Canvas Layer\n",
    "                if self.is_drawing and self.prev_x != 0:\n",
    "                    # Draw line on the canvas layer (Blue color, thickness 5)\n",
    "                    cv2.line(self.canvas_layer, \n",
    "                             (self.prev_x, self.prev_y), \n",
    "                             (self.current_x, self.current_y), \n",
    "                             (255, 0, 0), \n",
    "                             thickness=5)\n",
    "                \n",
    "                # e. Update previous position for the next frame\n",
    "                self.prev_x, self.prev_y = self.current_x, self.current_y\n",
    "                \n",
    "                # f. Draw ALL landmarks (optional visual feedback)\n",
    "                for lm in hand_landmarks:\n",
    "                    cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                    cv2.circle(frame, (cx, cy), 2, (0, 255, 255), -1)\n",
    "\n",
    "        else:\n",
    "            # If no hand is detected, ensure drawing is off and reset previous position\n",
    "            self.is_drawing = False\n",
    "            self.prev_x, self.prev_y = 0, 0\n",
    "\n",
    "\n",
    "        # 6. Combine the Video Frame and the Canvas Layer\n",
    "        frame = cv2.addWeighted(frame, 1.0, self.canvas_layer, 1.0, 0)\n",
    "\n",
    "        # 7. Update and Draw FPS\n",
    "        self.frame_count += 1\n",
    "        elapsed = time.time() - self.fps_start_time\n",
    "        if elapsed > 1.0:\n",
    "            self.fps = self.frame_count / elapsed\n",
    "            self.fps_start_time = time.time()\n",
    "            self.frame_count = 0\n",
    "\n",
    "        cv2.putText(frame, f\"FPS: {self.fps:.1f}\", (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Mode: {'DRAWING' if self.is_drawing else 'MOVING'}\", (10, 80),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "        # 8. Convert the final frame to QImage and display\n",
    "        rgb_display = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        h, w, ch = rgb_display.shape\n",
    "        bytes_per_line = ch * w\n",
    "        qimg = QImage(rgb_display.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)\n",
    "        pixmap = QPixmap.fromImage(qimg)\n",
    "        self.video_label.setPixmap(pixmap)\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # Cleanup resources\n",
    "    # -----------------------------------------------\n",
    "    def closeEvent(self, event):\n",
    "        self.timer.stop()\n",
    "        self.cap.release()\n",
    "        try:\n",
    "            hand_landmarker.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "        event.accept()\n",
    "\n",
    "# ============================================================\n",
    "# III. Main entry point\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = AirCanvasApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08950d6d-d596-48fc-b53c-6886c18d972a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
